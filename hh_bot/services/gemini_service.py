"""
ðŸ¤– Ð¡ÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Gemini AI
"""

import json
import requests
import logging
from typing import Dict, Optional, Tuple, List
import traceback
from pathlib import Path

from ..config.settings import settings, AppConstants
from ..models.vacancy import Vacancy

logger = logging.getLogger(__name__)


class GeminiApiClient:
    """ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Gemini API"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = AppConstants.GEMINI_BASE_URL
        self.model = AppConstants.GEMINI_MODEL

    def generate_content(self, prompt: str) -> Optional[Dict]:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð° Ñ‡ÐµÑ€ÐµÐ· Gemini API"""
        url = f"{self.base_url}/models/{self.model}:generateContent"

        headers = {"Content-Type": "application/json"}
        params = {"key": self.api_key}

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": AppConstants.GEMINI_TEMPERATURE,
                "maxOutputTokens": AppConstants.GEMINI_MAX_OUTPUT_TOKENS,
            },
        }

        try:
            logger.info("ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Gemini API")
            response = requests.post(
                url,
                headers=headers,
                params=params,
                json=payload,
                timeout=AppConstants.DEFAULT_TIMEOUT,
            )

            if response.status_code != 200:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° API Gemini: {response.status_code}, {response.text}")
                return None

            result = response.json()
            return self._parse_response(result)

        except requests.RequestException as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ‚Ð¸ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ðº Gemini: {e}")
            return None
        except Exception as e:
            logger.error(f"ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Gemini API: {e}")
            return None

    def _parse_response(self, result: Dict) -> Optional[Dict]:
        """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Gemini API"""
        try:
            if "candidates" not in result or not result["candidates"]:
                logger.warning("ÐŸÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Gemini")
                return None

            content = result["candidates"][0]["content"]["parts"][0]["text"]
            return self._extract_json_from_text(content)

        except (KeyError, IndexError) as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Gemini: {e}")
            return None

    def _extract_json_from_text(self, content: str) -> Optional[Dict]:
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ JSON Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°"""
        try:
            json_start = content.find("{")
            json_end = content.rfind("}") + 1

            if json_start >= 0 and json_end > json_start:
                json_str = content[json_start:json_end]
                parsed_response = json.loads(json_str)

                score = parsed_response.get("match_score", 0)
                logger.info(f"Gemini Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½: {score}")
                return parsed_response
            else:
                logger.error("JSON Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ðµ Gemini")
                return None

        except json.JSONDecodeError as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° JSON Ð¾Ñ‚ Gemini: {e}")
            logger.debug(f"ÐšÐ¾Ð½Ñ‚ÐµÐ½Ñ‚: {content}")
            return None


class ResumeDataLoader:
    """Ð—Ð°Ð³Ñ€ÑƒÐ·Ñ‡Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð²"""

    def __init__(self):
        self._cache: Optional[Dict[str, str]] = None

    def load(self) -> Dict[str, str]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ñ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼"""
        if self._cache is not None:
            return self._cache

        try:
            resume_data = self._load_from_files()
            self._cache = resume_data
            return resume_data
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ€ÐµÐ·ÑŽÐ¼Ðµ: {e}")
            return self._get_default_resume_data()

    def _load_from_files(self) -> Dict[str, str]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð²"""
        resume_data = {}

        file_mappings = {
            "experience": settings.resume.experience_file,
            "about_me": settings.resume.about_me_file,
            "skills": settings.resume.skills_file,
        }

        for key, relative_path in file_mappings.items():
            file_path = self._get_file_path(relative_path)

            if file_path.exists():
                resume_data[key] = file_path.read_text(encoding="utf-8")
                logger.info(f"Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½ {key} Ð¸Ð· {file_path}")
            else:
                resume_data[key] = self._get_default_value(key)
                logger.warning(f"Ð¤Ð°Ð¹Ð» {file_path} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ")

        return resume_data

    def _get_file_path(self, relative_path: str) -> Path:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¾Ð³Ð¾ Ð¿ÑƒÑ‚Ð¸ Ðº Ñ„Ð°Ð¹Ð»Ñƒ"""
        if Path(relative_path).is_absolute():
            return Path(relative_path)
        return Path.cwd() / relative_path

    def _get_default_value(self, key: str) -> str:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ"""
        defaults = {
            "experience": "Ð‘ÐµÐ· Ð¾Ð¿Ñ‹Ñ‚Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹. ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽÑ‰Ð¸Ð¹ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº.",
            "about_me": "ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽÑ‰Ð¸Ð¹ Python Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº, Ð¸Ð·ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ.",
            "skills": "Python, SQL, Git, Ð¾ÑÐ½Ð¾Ð²Ñ‹ Ð²ÐµÐ±-Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸",
        }
        return defaults.get(key, "ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾")

    def _get_default_resume_data(self) -> Dict[str, str]:
        """ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ"""
        return {
            "experience": self._get_default_value("experience"),
            "about_me": self._get_default_value("about_me"),
            "skills": self._get_default_value("skills"),
        }


class VacancyAnalyzer:
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¹"""

    def __init__(self, api_client: GeminiApiClient, resume_loader: ResumeDataLoader):
        self.api_client = api_client
        self.resume_loader = resume_loader
        self.match_threshold = settings.gemini.match_threshold

    def analyze(self, vacancy: Vacancy) -> Tuple[float, List[str]]:
        """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸ Ñ€ÐµÐ·ÑŽÐ¼Ðµ"""
        try:
            resume_data = self.resume_loader.load()
            prompt = self._create_prompt(vacancy, resume_data)

            response = self.api_client.generate_content(prompt)

            if response and "match_score" in response:
                score = float(response["match_score"])
                reasons = response.get("match_reasons", ["AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½"])
                return self._validate_score(score), reasons
            else:
                logger.warning("ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Gemini, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ")
                return self._basic_analysis(vacancy)

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ Gemini: {e}")
            logger.debug(f"Traceback: {traceback.format_exc()}")
            return self._basic_analysis(vacancy)

    def _create_prompt(self, vacancy: Vacancy, resume_data: Dict[str, str]) -> str:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ"""
        prompt = f"""
ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñƒ Ñ€ÐµÐ·ÑŽÐ¼Ðµ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° Ð¸ Ð²Ð°ÐºÐ°Ð½ÑÐ¸ÐµÐ¹.
Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ñ Ñ‚Ð°ÐºÐ¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¾Ð¹:
{{
    "match_score": 0.85,
    "match_reasons": ["Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°1", "Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°2"],
    "recommendation": "ÑÑ‚Ð¾Ð¸Ñ‚ Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ°Ñ‚ÑŒÑÑ"
}}

Ð Ð•Ð—Ð®ÐœÐ• ÐšÐÐÐ”Ð˜Ð”ÐÐ¢Ð:
ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: {resume_data.get('experience', 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½')}
Ðž ÑÐµÐ±Ðµ: {resume_data.get('about_me', 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾')}
ÐÐ°Ð²Ñ‹ÐºÐ¸: {resume_data.get('skills', 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹')}

Ð’ÐÐšÐÐÐ¡Ð˜Ð¯:
ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ: {vacancy.name}
ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ: {vacancy.employer.name}
Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ: {vacancy.snippet.requirement or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'}
ÐžÐ±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸: {vacancy.snippet.responsibility or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'}
ÐžÐ¿Ñ‹Ñ‚: {vacancy.experience.name}

ÐžÑ†ÐµÐ½Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¾Ñ‚ {AppConstants.MIN_AI_SCORE} Ð´Ð¾ {AppConstants.MAX_AI_SCORE}, Ð³Ð´Ðµ:
- 0.0-0.3: ÐÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚
- 0.4-0.6: Ð§Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚
- 0.7-0.9: Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚
- 0.9-1.0: ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚

Ð’ match_reasons ÑƒÐºÐ°Ð¶Ð¸ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð¾Ñ†ÐµÐ½ÐºÐ¸.
Ð’ recommendation: "ÑÑ‚Ð¾Ð¸Ñ‚ Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ°Ñ‚ÑŒÑÑ", "ÑÑ‚Ð¾Ð¸Ñ‚ Ð¿Ð¾Ð´ÑƒÐ¼Ð°Ñ‚ÑŒ" Ð¸Ð»Ð¸ "Ð½Ðµ ÑÑ‚Ð¾Ð¸Ñ‚ Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ°Ñ‚ÑŒÑÑ".
"""
        return prompt.strip()

    def _validate_score(self, score: float) -> float:
        """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ AI"""
        return max(AppConstants.MIN_AI_SCORE, min(AppConstants.MAX_AI_SCORE, score))

    def _basic_analysis(self, vacancy: Vacancy) -> Tuple[float, List[str]]:
        """Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð±ÐµÐ· AI (Ñ„Ð¾Ð»Ð±ÑÐº)"""
        score = 0.0
        reasons = []

        try:

            if vacancy.has_python():
                score += 0.4
                reasons.append("Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Python Ð² Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÑ…")
            else:
                reasons.append("ÐÐµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Python Ð² Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÑ…")
                return 0.1, reasons

            if vacancy.is_junior_level():
                score += 0.3
                reasons.append("ÐŸÐ¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ (junior)")
            elif vacancy.experience.id in ["noExperience", "between1And3"]:
                score += 0.2
                reasons.append("ÐŸÑ€Ð¸ÐµÐ¼Ð»ÐµÐ¼Ñ‹Ð¹ Ð¾Ð¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹")

            if not vacancy.has_test:
                score += 0.1
                reasons.append("Ð‘ÐµÐ· Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ")
            else:
                reasons.append("Ð•ÑÑ‚ÑŒ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ")

            if not vacancy.archived:
                score += 0.1
                reasons.append("ÐÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð°Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ñ")

            return min(score, 1.0), reasons
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
            return 0.0, ["ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"]

    def should_apply(self, vacancy: Vacancy) -> bool:
        """ÐŸÑ€Ð¸Ð½ÑÑ‚Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¾ Ð¿Ð¾Ð´Ð°Ñ‡Ðµ Ð·Ð°ÑÐ²ÐºÐ¸"""
        try:
            score, reasons = self.analyze(vacancy)

            vacancy.ai_match_score = score
            vacancy.ai_match_reasons = reasons

            should_apply = score >= self.match_threshold

            if should_apply:
                logger.info(f"Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ°Ñ‚ÑŒÑÑ (score: {score:.2f})")
            else:
                logger.info(f"ÐÐµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ°Ñ‚ÑŒÑÑ (score: {score:.2f})")

            return should_apply
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² should_apply: {e}")
            return False


class GeminiAIService:
    """Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¹ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Gemini AI"""

    def __init__(self):
        self.api_key = settings.gemini.api_key

        if self.api_key:
            self.api_client = GeminiApiClient(self.api_key)
        else:
            self.api_client = None

        self.resume_loader = ResumeDataLoader()

        if self.api_client:
            self.analyzer = VacancyAnalyzer(self.api_client, self.resume_loader)
        else:
            self.analyzer = None

    def is_available(self) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ð¸ ÑÐµÑ€Ð²Ð¸ÑÐ°"""
        return bool(self.api_key)

    def load_resume_data(self) -> Dict[str, str]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð¾Ð²"""
        return self.resume_loader.load()

    def analyze_vacancy_match(self, vacancy: Vacancy) -> Tuple[float, List[str]]:
        """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸ Ñ€ÐµÐ·ÑŽÐ¼Ðµ"""
        if not self.is_available() or not self.analyzer:
            logger.warning("Gemini API Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ")
            return VacancyAnalyzer(None, self.resume_loader)._basic_analysis(vacancy)

        return self.analyzer.analyze(vacancy)

    def should_apply(self, vacancy: Vacancy) -> bool:
        """ÐŸÑ€Ð¸Ð½ÑÑ‚Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¾ Ð¿Ð¾Ð´Ð°Ñ‡Ðµ Ð·Ð°ÑÐ²ÐºÐ¸"""
        if not self.is_available() or not self.analyzer:

            score, _ = VacancyAnalyzer(None, self.resume_loader)._basic_analysis(vacancy)
            return score >= settings.gemini.match_threshold

        return self.analyzer.should_apply(vacancy)
